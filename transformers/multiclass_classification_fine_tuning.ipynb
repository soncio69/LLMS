{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e752339-be24-49cc-b97b-1429f314177a",
   "metadata": {},
   "source": [
    "# FINE TUNING PER MULTICLASS CLASSIFICATION\n",
    "\n",
    "A differenza del precedente notebook, viene effettuato il fine tuning per effettuare la classificazione su 5 possibili labels anzichè 2.\n",
    "\n",
    "Per il resto gli step  sono analoghi\n",
    "\n",
    "E' necessario scaricare un dataset con 5 possibili labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e096a54-7eae-4705-abb4-8bf5d8828f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c195c3e7e94a1d97e03455c57db35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da465e4a5d4949269ca10acaadfc380f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "yelp_review_full/train-00000-of-00001.pa(…):   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b165d9276b2c4b159c6ed769458c15c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "yelp_review_full/test-00000-of-00001.par(…):   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6498754845224db0bec9e170a7393af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74ac810fa19468481c7a73f45285689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loads Yelp Reviews dataset with ratings from 1 to 5 \n",
    "dataset = load_dataset(\"yelp_review_full\") \n",
    "\n",
    "# Displays the structure of the dataset \n",
    "print(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a227c9e-a773-4482-8362-13a0080452e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f758570ad71447f7824a21f2715c1bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edbaaa068914569834941ec133818ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Selects the train and test splits\n",
    "train_dataset = dataset[\"train\"] \n",
    "test_dataset = dataset[\"test\"] \n",
    "\n",
    "\n",
    "# Filters for restaurant-related reviews in the train and test datasets \n",
    "restaurant_train_reviews = train_dataset.filter( \n",
    "    lambda x: \"restaurant\" in x[\"text\"].lower()\n",
    ")\n",
    "restaurant_test_reviews = test_dataset.filter(\n",
    "    lambda x: \"restaurant\" in x[\"text\"].lower()\n",
    ")\n",
    "\n",
    "# Uses only 5,000 reviews for training \n",
    "number_of_reviews = 5000 \n",
    "subset_train_reviews = restaurant_train_reviews.shuffle(\n",
    "    seed=42).select(range(number_of_reviews))\n",
    "subset_test_reviews = restaurant_test_reviews.shuffle(\n",
    "    seed=42).select(range(number_of_reviews))\n",
    "\n",
    "# Creates a DatasetDict to return both train and test datasets \n",
    "subset_dataset = { \n",
    "    \"train\": subset_train_reviews,\n",
    "    \"test\": subset_test_reviews\n",
    "}\n",
    "\n",
    "# Displays the structure to match the requested format \n",
    "yelp_restaurant_dataset = DatasetDict(subset_dataset) \n",
    "\n",
    "# Prints the dataset structure \n",
    "print(yelp_restaurant_dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a414531c-2fc4-4740-8b06-d57ff2967665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"This place is good, but I think I just ordered the wrong thing. The Hibiscus Enchiladas were just way too sweet for me. I think they should be on the dessert menu and not dinner menu. I'd like to give it another chance and order something else next time, but other than that a good vibe. Seemed like the typical American Mexican restaurant.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_restaurant_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47010347-f2e9-4ea5-b3cb-dcb51d28a12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b248c87f038d43548be2a1dced53d4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782eba2f55324312bed7984a38acd481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)  #1\n",
    "\n",
    "def tokenize_function(examples):  #2\n",
    "    return tokenizer(examples[\"text\"],\n",
    "                     padding = \"max_length\",\n",
    "                     truncation = True,\n",
    "                     max_length = 512)\n",
    "\n",
    "tokenized_datasets = yelp_restaurant_dataset.map(  #3\n",
    "                         tokenize_function,\n",
    "                         batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0947e30-827d-44e9-afdb-855ba0a2dc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(  #1\n",
    "            model_checkpoint,\n",
    "            num_labels = 5)\n",
    "\n",
    "# Determines the device \n",
    "if torch.backends.mps.is_available(): \n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Moves the model to the selected device \n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cc206-1b75-46e3-a6a3-38feb1d32f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Sets up training arguments \n",
    "training_args = TrainingArguments( \n",
    "    output_dir = \"./results\",  # Directory in which to save results \n",
    "    eval_strategy = \"epoch\",  # Evaluates model after each epoch \n",
    "    save_strategy = \"epoch\",  # Saves the model after each epoch \n",
    "    learning_rate = 2e-5,  # Learning rate \n",
    "    per_device_train_batch_size = 16,  # Batch size for training \n",
    "    per_device_eval_batch_size = 16,  # Batch size for evaluation \n",
    "    num_train_epochs = 3,  # Number of training epochs \n",
    "    weight_decay = 0.01,  # Weight decay for regularization \n",
    "    logging_dir = \"./logs\",  # Directory for logs \n",
    "    logging_steps = 10,  # Logs every 10 steps \n",
    "    save_steps = 500,  # Saves the model every 500 steps \n",
    "    load_best_model_at_end = True,  # Loads the best model at the end of training \n",
    ")\n",
    "\n",
    "# Sets up the Trainer \n",
    "trainer = Trainer( \n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "# Fine-tunes the model \n",
    "trainer.train()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98228ea-4d7c-4870-b4cb-30e8a8eec871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Saves the fine-tuned model and tokenizer \n",
    "model.save_pretrained(\"./results/final_model_multiclass\") \n",
    "tokenizer.save_pretrained(\"./results/final_tokenizer_multiclass\")  \n",
    "\n",
    "#2 Evaluates the model on the test set \n",
    "eval_results = trainer.evaluate()  \n",
    "\n",
    "#3 Prints the evaluation results \n",
    "print(eval_results)  #3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
